{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.7/site-packages (4.5.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/anaconda3/lib/python3.7/site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from plotly) (1.12.0)\n",
      "Requirement already satisfied: termcolor in /opt/anaconda3/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: wordcloud in /opt/anaconda3/lib/python3.7/site-packages (1.6.0)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.7/site-packages (from wordcloud) (6.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.7/site-packages (from wordcloud) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from wordcloud) (1.17.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->wordcloud) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->wordcloud) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (41.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "import regex as re\n",
    "import collections\n",
    "!pip install plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "!pip install termcolor\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "!pip install wordcloud\n",
    "import os\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "import regex as re\n",
    "\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.metrics import r2_score,mean_squared_error,confusion_matrix,accuracy_score\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,HashingVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import WordPunctTokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering <a id='datagathering'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LA and NYC Reddit Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to get the submissions, all the posts on a subreddit, comments are what is in a post\n",
    "#size = 500 gives us 500 posts\n",
    "#we are predicting the subreddit posts are coming from, the limit is 500 so we get 5 iterations to get a good size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pushshift(subreddit, kind='submission', skip=30, times=5, \n",
    "                    #30 day increment, times = # of times collecting from increment\n",
    "                    subfield = ['title', 'selftext', 'subreddit', 'created_utc', 'author', 'num_comments', \n",
    "                                'score', 'is_self'],\n",
    "                    comfields = ['body', 'score', 'created_utc']):\n",
    "    stem = \"https://api.pushshift.io/reddit/search/{}/?subreddit={}&size=500\".format(kind, subreddit)\n",
    "    mylist = [] #30 day list of 500 posts, 30,60,120,150,180 (5 iterations)\n",
    "    for x in range(1, times + 1):\n",
    "        URL = \"{}&after={}d\".format(stem, skip * x)\n",
    "        print(URL)\n",
    "        response = requests.get(URL) #scraping that returns text shape as dictionary\n",
    "        assert response.status_code == 200 #checks status code to make sure not rejected\n",
    "        mine = response.json()['data'] #takes that text and creates dataframe\n",
    "        df = pd.DataFrame.from_dict(mine) \n",
    "        mylist.append(df)\n",
    "        time.sleep(2) #dont get booted\n",
    "    full = pd.concat(mylist, sort=False)\n",
    "    if kind == \"submission\":\n",
    "        full = full[subfield]\n",
    "        full = full.drop_duplicates(subset = 'title')\n",
    "        full = full.loc[full['is_self'] == True]\n",
    "    def get_date(created):\n",
    "        return dt.date.fromtimestamp(created)\n",
    "    _timestamp = full[\"created_utc\"].apply(get_date)\n",
    "    full['timestamp'] = _timestamp\n",
    "    print(full.shape)\n",
    "    return full "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?subreddit=nyc&size=500&after=30d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=nyc&size=500&after=60d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=nyc&size=500&after=90d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=nyc&size=500&after=120d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=nyc&size=500&after=150d\n",
      "(837, 9)\n"
     ]
    }
   ],
   "source": [
    "nyc_query = query_pushshift('nyc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?subreddit=LosAngeles&size=500&after=30d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=LosAngeles&size=500&after=60d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=LosAngeles&size=500&after=90d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=LosAngeles&size=500&after=120d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=LosAngeles&size=500&after=150d\n",
      "(1021, 9)\n"
     ]
    }
   ],
   "source": [
    "la_query = query_pushshift('LosAngeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looking For A Good Time Tonight?</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1578117034</td>\n",
       "      <td>Asians4life1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Help pls! Where can I find a comedy merch stor...</td>\n",
       "      <td>Hey everyone living in New York,\\n\\nis there a...</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1578131446</td>\n",
       "      <td>djlazybird</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Finding Cannabis in NYC</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1578149173</td>\n",
       "      <td>panopticsjpp</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What do I do if both parking meters on my side...</td>\n",
       "      <td>Do I go around the block and print a ticket fr...</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1578149783</td>\n",
       "      <td>bigmoe_7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Upper West Side breakfast/bagel recommendations</td>\n",
       "      <td>I’ll be spending next weekend in NYC, and stay...</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1578154649</td>\n",
       "      <td>lowndest</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                    Looking For A Good Time Tonight?   \n",
       "2   Help pls! Where can I find a comedy merch stor...   \n",
       "10                            Finding Cannabis in NYC   \n",
       "11  What do I do if both parking meters on my side...   \n",
       "16    Upper West Side breakfast/bagel recommendations   \n",
       "\n",
       "                                             selftext subreddit  created_utc  \\\n",
       "0                                           [removed]       nyc   1578117034   \n",
       "2   Hey everyone living in New York,\\n\\nis there a...       nyc   1578131446   \n",
       "10                                          [removed]       nyc   1578149173   \n",
       "11  Do I go around the block and print a ticket fr...       nyc   1578149783   \n",
       "16  I’ll be spending next weekend in NYC, and stay...       nyc   1578154649   \n",
       "\n",
       "          author  num_comments  score  is_self   timestamp  \n",
       "0   Asians4life1             6      0     True  2020-01-04  \n",
       "2     djlazybird            16      0     True  2020-01-04  \n",
       "10  panopticsjpp            39      0     True  2020-01-04  \n",
       "11      bigmoe_7             8      1     True  2020-01-04  \n",
       "16      lowndest            22      0     True  2020-01-04  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>? about water bill in apartment</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1578114247</td>\n",
       "      <td>shitty_bang_bang</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Equinox Westwood Member</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1578116126</td>\n",
       "      <td>costcoquestions</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phone mugging on PICO/HAUSER bus stop</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1578120596</td>\n",
       "      <td>jiggyelephante</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Solo trip to LA from Miami? What to see and do?</td>\n",
       "      <td></td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1578120955</td>\n",
       "      <td>shitheadboot1122</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Petition to ban VoteTurnoutNoBurnout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1578121860</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title   selftext   subreddit  \\\n",
       "1                  ? about water bill in apartment  [removed]  LosAngeles   \n",
       "2                          Equinox Westwood Member  [removed]  LosAngeles   \n",
       "5            Phone mugging on PICO/HAUSER bus stop  [removed]  LosAngeles   \n",
       "6  Solo trip to LA from Miami? What to see and do?             LosAngeles   \n",
       "7             Petition to ban VoteTurnoutNoBurnout        NaN  LosAngeles   \n",
       "\n",
       "   created_utc            author  num_comments  score  is_self   timestamp  \n",
       "1   1578114247  shitty_bang_bang             2      1     True  2020-01-04  \n",
       "2   1578116126   costcoquestions             0      1     True  2020-01-04  \n",
       "5   1578120596    jiggyelephante             2      1     True  2020-01-04  \n",
       "6   1578120955  shitheadboot1122             8      0     True  2020-01-04  \n",
       "7   1578121860         [deleted]             2      1     True  2020-01-04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_query.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary EDA<a id='prelimeda'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our Los Angeles query dataframe is (1021, 9)\n",
      "The size of our NYC query dataframe is (837, 9)\n"
     ]
    }
   ],
   "source": [
    "print('The size of our Los Angeles query dataframe is ' + str(la_query.shape))\n",
    "print('The size of our NYC query dataframe is ' + str(nyc_query.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: Dataset is uneven, with more datapoints for LA than NYC, therefore our LA model will be better trained as it has more data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLA Query Data Types\n",
      "\u001b[0m\n",
      "title           object\n",
      "selftext        object\n",
      "subreddit       object\n",
      "created_utc      int64\n",
      "author          object\n",
      "num_comments     int64\n",
      "score            int64\n",
      "is_self           bool\n",
      "timestamp       object\n",
      "dtype: object\n",
      "\u001b[1m\n",
      "NYC Query Data Types\n",
      "\u001b[0m\n",
      "title           object\n",
      "selftext        object\n",
      "subreddit       object\n",
      "created_utc      int64\n",
      "author          object\n",
      "num_comments     int64\n",
      "score            int64\n",
      "is_self           bool\n",
      "timestamp       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(colored('LA Query Data Types' '\\n', attrs=['bold']))\n",
    "print(la_query.dtypes)\n",
    "\n",
    "print(colored('\\n''NYC Query Data Types' '\\n', attrs=['bold']))\n",
    "print(nyc_query.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNYC Query Null Counts\n",
      "\u001b[0m\n",
      "title           0\n",
      "selftext        0\n",
      "subreddit       0\n",
      "created_utc     0\n",
      "author          0\n",
      "num_comments    0\n",
      "score           0\n",
      "is_self         0\n",
      "timestamp       0\n",
      "dtype: int64\n",
      "\u001b[1m\n",
      "LA Query Null Counts\n",
      "\u001b[0m\n",
      "title            0\n",
      "selftext        10\n",
      "subreddit        0\n",
      "created_utc      0\n",
      "author           0\n",
      "num_comments     0\n",
      "score            0\n",
      "is_self          0\n",
      "timestamp        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(colored('NYC Query Null Counts' + '\\n', attrs = ['bold']))\n",
    "print(str(nyc_query.isnull().sum()))\n",
    "print(colored('\\n' + 'LA Query Null Counts' '\\n', attrs = ['bold']))\n",
    "print(str(la_query.isnull().sum()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(string):\n",
    "    \n",
    "    #We want letters only\n",
    "    string = re.sub(\"[^a-zA-Z]\", \" \", string) \n",
    "    \n",
    "    #removing hyperlinks\n",
    "    string = re.sub(r'http\\S+', '', string)\n",
    "    string = re.sub(r'www\\S+', '', string)\n",
    "   \n",
    "    #converts words to lowercase and splits.\n",
    "    string = string.lower().split()\n",
    "    \n",
    "    #Instantiates lemmatizer and stems words.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    string = [lemmatizer.lemmatize(x) for x in string]\n",
    "    \n",
    "    #Creating variable form default english stopword list and our own custom stop list.\n",
    "    stop = set(stopwords.words('english'))\n",
    "    custom_stop = ['la', 'los' ,'angeles', 'nyc', 'ny', 'ca', 'california' ,'cali', 'york', 'new', 'anyone', 'best', 'city',\n",
    "                   'place', 'get', 'know', 'looking', 'people', 'good', 'time', 'wa', 'like', 'question', 'need', 'th', 'area',\n",
    "                   'day', 'today', 'go', 'one', 'find', 'ha']\n",
    "                   \n",
    "    \n",
    "    #removing stopwords from both the default english set, and our custom stop word list\n",
    "    string = [x for x in string if not x in stop]\n",
    "    string = [w for w in string if not w in custom_stop]\n",
    "    \n",
    "\n",
    "    #joining words separated by a space and return\n",
    "    return(\" \".join(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying our cleaning function to columns which can be our features. \n",
    "nyc_query['title'] = nyc_query['title'].apply(preprocess)\n",
    "nyc_query['selftext'] = nyc_query['title'].apply(preprocess)\n",
    "la_query['title'] = la_query['title'].apply(preprocess)\n",
    "la_query['selftext'] = la_query['title'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns that will not contribute to our model\n",
    "nyc_query.drop(['created_utc', 'author', 'num_comments', 'score', 'is_self', 'timestamp'], axis=1, inplace=True)\n",
    "la_query.drop(['created_utc', 'author', 'num_comments', 'score', 'is_self', 'timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water bill apartment</td>\n",
       "      <td>water bill apartment</td>\n",
       "      <td>LosAngeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>equinox westwood member</td>\n",
       "      <td>equinox westwood member</td>\n",
       "      <td>LosAngeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phone mugging pico hauser bus stop</td>\n",
       "      <td>phone mugging pico hauser bus stop</td>\n",
       "      <td>LosAngeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>solo trip miami see</td>\n",
       "      <td>solo trip miami see</td>\n",
       "      <td>LosAngeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>petition ban voteturnoutnoburnout</td>\n",
       "      <td>petition ban voteturnoutnoburnout</td>\n",
       "      <td>LosAngeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title                            selftext  \\\n",
       "1                water bill apartment                water bill apartment   \n",
       "2             equinox westwood member             equinox westwood member   \n",
       "5  phone mugging pico hauser bus stop  phone mugging pico hauser bus stop   \n",
       "6                 solo trip miami see                 solo trip miami see   \n",
       "7   petition ban voteturnoutnoburnout   petition ban voteturnoutnoburnout   \n",
       "\n",
       "    subreddit  \n",
       "1  LosAngeles  \n",
       "2  LosAngeles  \n",
       "5  LosAngeles  \n",
       "6  LosAngeles  \n",
       "7  LosAngeles  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a list of the dataframes we are merging and then merging\n",
    "to_merge = [la_query, nyc_query]\n",
    "nyc_la = pd.concat(to_merge)\n",
    "\n",
    "#converting to csv then printing .head to make sure columns are as expected \n",
    "nyc_query.to_csv('./Project_Files/Datasets/nyc_query.csv', index = False)\n",
    "la_query.to_csv('./Project_Files/Datasets/la_query.csv', index = False)\n",
    "nyc_la.to_csv('./Project_Files/Datasets/nyc_la.csv', index = False)\n",
    "nyc_la.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LosAngeles</th>\n",
       "      <td>1021</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyc</th>\n",
       "      <td>837</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  selftext\n",
       "subreddit                  \n",
       "LosAngeles   1021      1021\n",
       "nyc           837       837"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value counts are as expected\n",
    "nyc_la.groupby('subreddit').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
